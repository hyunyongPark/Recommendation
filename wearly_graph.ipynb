{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wearly_graph.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM7GkwMiDOCXTpqfWBXtq4S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyunyongPark/Recommendation/blob/master/wearly_graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07pqtb2Ut6t4",
        "colab_type": "text"
      },
      "source": [
        "# **1. data load & preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuhoDw_VfnGY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0f739b5f-8bad-4327-a217-d0a31630b4a8"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbGo3zPIfnEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-p3E2qwfnCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==1.7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-RZpTRkharW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d228abc3-acde-46b9-f0be-fdadf629b842"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import time\n",
        "from collections import deque\n",
        "\n",
        "import tensorflow as tf\n",
        "from six import next\n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "from scipy.sparse import lil_matrix\n",
        "from scipy.sparse import coo_matrix\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.7.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQAX_bR3gWou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "89d399b1-ddda-45e8-c99a-7473d43993c1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVRLXvn9BFfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_userANDrate():\n",
        "  credentials = \"postgresql://jczdtzmaouemml:f3f55cc0c6bd25a42866864c9299f4ec79ff4ff890f6f69467e2b14dc0010074@ec2-3-215-207-12.compute-1.amazonaws.com:5432/de8i6u9p9i6vq8\"\n",
        "  dbdf = pd.read_sql(\"\"\"select distinct * from wearly_user where age <= 70 order by idx \"\"\", con = credentials)\n",
        "  item = pd.read_sql(\"\"\"select * from wearly_wear\"\"\", con = credentials)\n",
        "  df = dbdf.copy()\n",
        "  df = df.drop_duplicates(['name', 'gender', 'age']+ df.columns.tolist()[4:-1], keep='first').reset_index(drop=False)\n",
        "  df = df.drop(['index','name','idx','time'], axis=1 , inplace=False)\n",
        "  \n",
        "  v = [data_row.values.tolist()[2:] for index, data_row in df.iterrows()]\n",
        "  vv = [v[i][j] for i in range(len(v)) for j in range(len(v[i]))]\n",
        "\n",
        "  user_rt = pd.DataFrame(index=range(0,len(df)*100) , columns=['user','image_file_name', 'rate'])\n",
        "  user_rt['user'] = sorted([i for i in range(0,len(df)) for j in range(0,100)])\n",
        "  user_rt['image_file_name'] = vv\n",
        "\n",
        "  for i in range(len(user_rt)):\n",
        "    user_rt['rate'][i] = int(user_rt['image_file_name'][i][-1])\n",
        "    user_rt['image_file_name'][i] = str(user_rt['image_file_name'][i][:-1])\n",
        "  \n",
        "  user_rt = user_rt.sample(frac=1, random_state=200).reset_index(drop=True)\n",
        "  user_rt = user_rt.merge(item[['image_id', 'image_file_name']], on='image_file_name')\n",
        "  \n",
        "  for i in range(len(user_rt)):\n",
        "    if user_rt['rate'][i] == 3:\n",
        "      user_rt['rate'][i] = 2\n",
        "    elif user_rt['rate'][i] == 5:\n",
        "      user_rt['rate'][i] = 3\n",
        "    else:\n",
        "      user_rt['rate'][i] = user_rt['rate'][i] \n",
        "\n",
        "    PERC = 0.9\n",
        "    rows = len(user_rt)\n",
        "    split_index = int(rows * PERC)\n",
        "    df_train = user_rt[0:split_index]\n",
        "    df_test = user_rt[split_index:].reset_index(drop=True)\n",
        "    \n",
        "    user_mt = df[['age','gender']]\n",
        "    user_mt = user_mt.reset_index()\n",
        "    user_mt['user'] = user_mt['index']\n",
        "    user_mt = user_mt[['user', 'age', 'gender']]\n",
        "    \n",
        "  return user_mt , user_rt, df_train, df_test , item\n",
        "\n",
        "user_mt, user_rt , df_train, df_test, item = make_userANDrate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja0_TRI10S9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## user_mt  one_hot encoding\n",
        "user_mt2 = pd.get_dummies(user_mt, columns=[ \"age\", \"gender\"])\n",
        "user_mt2 = user_mt2.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTxOZ6EoVn2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "item2 = item.drop(['idx', 'post_id', 'hashtag_crawl', 'account_name', 'image_file_name'], axis=1, inplace=False)\n",
        "item2 = item2.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nr-TROaWpa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = df_train[['user','image_id', 'rate']]\n",
        "test = df_test[['user','image_id', 'rate']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC0q6W6WtxcO",
        "colab_type": "text"
      },
      "source": [
        "# **2. GraphRec modeling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0boRp-vfm2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ShuffleIterator(object): \n",
        "\n",
        "    def __init__(self, inputs, batch_size=10):\n",
        "        self.inputs = inputs\n",
        "        self.batch_size = batch_size\n",
        "        self.num_cols = len(self.inputs)  # 행의 갯수\n",
        "        self.len = len(self.inputs[0]) # 열의 갯수\n",
        "        self.inputs = np.transpose(np.vstack([np.array(self.inputs[i]) for i in range(self.num_cols)])) # inputs가 i마다 밑으로 쌓임. -> 그걸 전치시킴\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        return self.next()\n",
        "\n",
        "    def next(self):  \n",
        "        ids = np.random.randint(0, self.len, (self.batch_size,))  # 0부터 기존행의개수까지 배치사이즈만큼 랜덤정수뽑음\n",
        "        out = self.inputs[ids, :] # 이런 랜덤정수index에 해당하는 모든 열   ->   열*행에서 열의 개수 만큼 뽑아냄\n",
        "        return [out[:, i] for i in range(self.num_cols)] # 열*행out에서 행의 넘버에 해당하는 모든 index를 뽑아냄 . 즉 원래모형으로 배치사이즈 크기에 값들이 셔플이 됨.  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z919L3BDfmwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OneEpochIterator(ShuffleIterator):\n",
        "    def __init__(self, inputs, batch_size=10):\n",
        "        super(OneEpochIterator, self).__init__(inputs, batch_size=batch_size) # 부모클래스의 inputs와 배치사이즈를 가져옴\n",
        "        if batch_size > 0:\n",
        "            self.idx_group = np.array_split(np.arange(self.len), np.ceil(self.len / batch_size))  # inputs길이크기의 array를 inputs길이/배치사이즈를 올림후의 크기의 갯수만큼 split하여 그 수만큼의 array 리스트 형성\n",
        "        else: # 배치사이즈 적용안할경우\n",
        "            self.idx_group = [np.arange(self.len)] \n",
        "        self.group_id = 0\n",
        "\n",
        "    def next(self):\n",
        "        if self.group_id >= len(self.idx_group):\n",
        "            self.group_id = 0\n",
        "            raise StopIteration\n",
        "        out = self.inputs[self.idx_group[self.group_id], :]\n",
        "        self.group_id += 1\n",
        "        return [out[:, i] for i in range(self.num_cols)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfUyF6gNfmuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inferenceDense(phase,user_batch, item_batch,idx_user,idx_item, user_num, item_num,UReg=0.05,IReg=0.1):\n",
        "    with tf.device(DEVICE):\n",
        "        user_batch = tf.nn.embedding_lookup(idx_user, user_batch, name=\"embedding_user\")\n",
        "        item_batch = tf.nn.embedding_lookup(idx_item, item_batch, name=\"embedding_item\")\n",
        "        \n",
        "        \n",
        "        ul1mf=tf.layers.dense(inputs=user_batch, units=MFSIZE,activation=tf.nn.crelu, kernel_initializer=tf.random_normal_initializer(stddev=0.01))\n",
        "        il1mf=tf.layers.dense(inputs=item_batch, units=MFSIZE,activation=tf.nn.crelu, kernel_initializer=tf.random_normal_initializer(stddev=0.01))\n",
        "        InferInputMF=tf.multiply(ul1mf, il1mf)\n",
        "\n",
        "\n",
        "        infer=tf.reduce_sum(InferInputMF, 1, name=\"inference\")\n",
        "\n",
        "        regularizer = tf.add(UW*tf.nn.l2_loss(ul1mf), IW*tf.nn.l2_loss(il1mf), name=\"regularizer\")\n",
        "\n",
        "    return InferInputMF, infer, regularizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6Mzqy6qfmsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimization(infer, regularizer, rate_batch, learning_rate=0.0005, reg=0.1):\n",
        "    with tf.device(DEVICE):\n",
        "        global_step = tf.train.get_global_step()\n",
        "        assert global_step is not None\n",
        "        cost_l2 = tf.nn.l2_loss(tf.subtract(infer, rate_batch))\n",
        "        cost = tf.add(cost_l2, regularizer)\n",
        "        train_op = tf.train.AdamOptimizer(learning_rate).minimize(cost, global_step=global_step)\n",
        "    return cost, train_op"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hxiXFeAfmfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clip(x):\n",
        "    return np.clip(x, 1.0, 3.0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKrIvuyNfjXR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GraphRec(train, test,ItmDat,UsrDat,Graph=True,Dataset='100k'):  # 아이템정보와 유저정보를 사용할지 말지를 정함.\n",
        "\n",
        "    AdjacencyUsers = np.zeros((USER_NUM,ITEM_NUM), dtype=np.float32) #np.asarray([[0 for x in range(ITEM_NUM)] for y in range(USER_NUM)],dtype=np.float16)\n",
        "    #print('AdjacencyUsers : ' , AdjacencyUsers.shape)  # (943, 1682)\n",
        "    DegreeUsers = np.zeros((USER_NUM,1), dtype=np.float32)# np.asarray([[0 for x in range(1)] for y in range(USER_NUM)],dtype=np.float16)\n",
        "    #print('DegreeUsers : ' , DegreeUsers.shape) # (943, 1)\n",
        "    AdjacencyItems = np.zeros((ITEM_NUM,USER_NUM), dtype=np.float32) #np.asarray([[0 for x in range(USER_NUM)] for y in range(ITEM_NUM)],dtype=np.float16)\n",
        "    #print('AdjacencyItems : ' , AdjacencyItems.shape) # (1682, 943)\n",
        "    DegreeItems =  np.zeros((ITEM_NUM,1), dtype=np.float32) #np.asarray([[0 for x in range(1)] for y in range(ITEM_NUM)],dtype=np.float16)\n",
        "    #print('DegreeItems : ' , DegreeItems.shape) # (1682, 1)\n",
        "    \n",
        "    for index, row in train.iterrows():\n",
        "      userid=int(row['user'])  # train의 user(길이9000)를 하나하나 접근 \n",
        "      itemid=int(row['image_id'])\n",
        "      \n",
        "      # 인접행렬 형성  \n",
        "      AdjacencyUsers[userid][itemid]=row['rate']/3.0   # 인접행렬 정규화   train의 rate를 max_rate로 나누어줌으로서 정규화\n",
        "      AdjacencyItems[itemid][userid]=row['rate']/3.0   # 이렇게 되면 결국 train에 존재하는 유저는 정규화된 평점이 찍히고 나머지는 0    /결국은 유저와 아이템의 rate기반 인접된 행렬 형성\n",
        "      \n",
        "      DegreeUsers[userid][0]+=1    # 중복된 user의 수를 볼수있음. 예를들면 userid가 880인데 for문돌면서 몇번나왔는지 찍힘.  \n",
        "      #print(userid, ' : ', DegreeUsers[userid])\n",
        "      DegreeItems[itemid][0]+=1  # 같은의미로 itemid의 등장빈도확인가능\n",
        "      #DegreeUsers shape : (943,1)   /  DegreeItems shape : (1682, 1)\n",
        "\n",
        "    DUserMax=np.amax(DegreeUsers)  # amax는 array의 최댓값 반환.   654    -> 제일 많이 등장한 user빈도가 \n",
        "    #print(DUserMax)\n",
        "    DItemMax=np.amax(DegreeItems)\n",
        "    DegreeUsers=np.true_divide(DegreeUsers, DUserMax) # np.true_divide는 나눗셈반환    (라플라시안 벡터 정규화 (공부필요))  \n",
        "    DegreeItems=np.true_divide(DegreeItems, DItemMax)\n",
        "    \n",
        "    # weighted AdjacencyUsers vec\n",
        "    AdjacencyUsers=np.asarray(AdjacencyUsers,dtype=np.float32)\n",
        "    AdjacencyItems=np.asarray(AdjacencyItems,dtype=np.float32)\n",
        "    print('인접행렬Au : ', AdjacencyUsers.shape)\n",
        "    print('인접행렬Ai : ',AdjacencyItems.shape)\n",
        "    if(Graph):   #943*943 + 943*1682 + 943*1          #1682*1682 + 1682*943 + 1682*1\n",
        "        UserFeatures= np.concatenate((np.identity(USER_NUM,dtype=np.bool_), AdjacencyUsers,DegreeUsers), axis=1) # L_u = Iu*Au*Du     실제로 저 단위정방행렬I는 없어도 됨.\n",
        "        ItemFeatures= np.concatenate((np.identity(ITEM_NUM,dtype=np.bool_), AdjacencyItems,DegreeItems), axis=1) # L_i = Iu*Au*Du\n",
        "    else:\n",
        "        UserFeatures=np.identity(USER_NUM,dtype=np.bool_) # 왜 이것만 썻냐면 만약 GraphRec에서의 핵심인 라플라시안행렬분해를 쓰지않으면 자기자신을 그대로 씀. 즉 UserFeature는 아래에서 X_u 그 자체가 되어버림.\n",
        "        ItemFeatures=np.identity(ITEM_NUM,dtype=np.bool_)\n",
        "\n",
        "    print('유저피처스1 : ',  UserFeatures)\n",
        "    print(UserFeatures.shape) # 943*2626\n",
        "\n",
        "    print('아이템피처스1 : ',  ItemFeatures)\n",
        "    print(ItemFeatures.shape) # 1682*2626\n",
        "\n",
        "    UserFeatures=np.concatenate((UserFeatures,UsrDat), axis=1)  # X_u\n",
        "\n",
        "    ItemFeatures=np.concatenate((ItemFeatures,ItmDat), axis=1) # X_i\n",
        "\n",
        "    UserFeaturesLength=UserFeatures.shape[1]\n",
        "    ItemFeaturesLength=ItemFeatures.shape[1]\n",
        "\n",
        "    print('유저피처스2 : ',  UserFeatures)\n",
        "    print('UserFeatures : ', UserFeatures.shape)\n",
        "    print('아이템피처스2 : ',  ItemFeatures)\n",
        "    print('ItemFeatures : ', ItemFeatures.shape)\n",
        "    # ---------------------------------\n",
        "    \n",
        "    samples_per_batch = len(train) // BATCH_SIZE\n",
        "\n",
        "    iter_train = ShuffleIterator([train[\"user\"],train[\"image_id\"],train[\"rate\"]],batch_size=BATCH_SIZE)\n",
        "\n",
        "    iter_test = OneEpochIterator([test[\"user\"],test[\"image_id\"],test[\"rate\"]],batch_size=10000)\n",
        "\n",
        "\n",
        "    user_batch = tf.placeholder(tf.int32, shape=[None], name=\"id_user\")  #int형 plac 선언\n",
        "    item_batch = tf.placeholder(tf.int32, shape=[None], name=\"id_item\")\n",
        "    rate_batch = tf.placeholder(tf.float64, shape=[None])\n",
        "    phase = tf.placeholder(tf.bool, name='phase')\n",
        "    \n",
        "    \n",
        "    w_user = tf.constant(UserFeatures,name=\"userids\", shape=[USER_NUM,UserFeatures.shape[1]],dtype=tf.float64) # shape = [943,2710] \n",
        "    w_item = tf.constant(ItemFeatures,name=\"itemids\", shape=[ITEM_NUM, ItemFeatures.shape[1]],dtype=tf.float64) # shape = [1682,2646]\n",
        "\n",
        "\n",
        "    InferInputMF , infer, regularizer = inferenceDense(phase,user_batch, item_batch,w_user,w_item, user_num=USER_NUM, item_num=ITEM_NUM)\n",
        "    global_step = tf.contrib.framework.get_or_create_global_step()\n",
        "    _, train_op = optimization(infer, regularizer, rate_batch, learning_rate=LR, reg=0.09)\n",
        "\n",
        "    init_op = tf.global_variables_initializer()\n",
        "    config = tf.ConfigProto()\n",
        "    config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "    finalerror=-1\n",
        "    with tf.Session(config=config) as sess:\n",
        "        sess.run(init_op)\n",
        "        print(\"{} {} {} {}\".format(\"epoch\", \"train_error\", \"val_error\", \"elapsed_time\"))\n",
        "        errors = deque(maxlen=samples_per_batch)\n",
        "        start = time.time()\n",
        "        for i in range(EPOCH_MAX * samples_per_batch):\n",
        "            #users, items, rates,y,m,d,dw,dy,w = next(iter_train)\n",
        "            users, items, rates = next(iter_train)\n",
        "            _, pred_batch = sess.run([train_op, infer], feed_dict={user_batch: users,\n",
        "                                                                   item_batch: items,\n",
        "                                                                   rate_batch: rates,\n",
        "                                                                   phase:True})\n",
        "            pred_batch = clip(pred_batch)\n",
        "            errors.append(np.power(pred_batch - rates, 2))\n",
        "            if i % samples_per_batch == 0:\n",
        "                train_err = np.sqrt(np.mean(errors))\n",
        "                test_err2 = np.array([])\n",
        "                degreelist=list()\n",
        "                predlist=list()\n",
        "                for users, items, rates in iter_test:\n",
        "                    pred_batch = sess.run(infer, feed_dict={user_batch: users,\n",
        "                                                            item_batch: items,                                                                                             \n",
        "                                                            phase:False})\n",
        "\n",
        "                    pred_batch = clip(pred_batch)            \n",
        "                    test_err2 = np.append(test_err2, np.power(pred_batch - rates, 2))\n",
        "                end = time.time()\n",
        "                test_err = np.sqrt(np.mean(test_err2))\n",
        "                finalerror=test_err\n",
        "                print(\"{:3d},{:f},{:f},{:f}(s)\".format(i // samples_per_batch, train_err, test_err, end - start))\n",
        "                start = end\n",
        "    return InferInputMF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z0RdM4uEq-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE=\"/CPU:0\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdV3kPC5AzKs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2ebda183-f16d-4546-8b93-eee7b0544696"
      },
      "source": [
        "BATCH_SIZE = 1000\n",
        "USER_NUM = len(user_mt2)\n",
        "ITEM_NUM = len(item2)\n",
        "\n",
        "\n",
        "MFSIZE=40\n",
        "UW=0.08\n",
        "IW=0.06\n",
        "LR=0.0002\n",
        "EPOCH_MAX = 50  #601\n",
        "tf.reset_default_graph()\n",
        "InferInputMF = GraphRec(train, test, item2, user_mt2, Graph=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "인접행렬Au :  (307, 7628)\n",
            "인접행렬Ai :  (7628, 307)\n",
            "유저피처스1 :  [[1.         0.         0.         ... 0.         0.         0.9484536 ]\n",
            " [0.         1.         0.         ... 0.         0.         0.96907216]\n",
            " [0.         0.         1.         ... 0.         0.         0.87628865]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.         0.         0.8659794 ]\n",
            " [0.         0.         0.         ... 0.         0.         0.9381443 ]\n",
            " [0.         0.         0.         ... 0.         0.         0.96907216]]\n",
            "(307, 7936)\n",
            "아이템피처스1 :  [[1.         0.         0.         ... 0.         0.         0.41666666]\n",
            " [0.         1.         0.         ... 0.         0.         0.5       ]\n",
            " [0.         0.         1.         ... 0.         0.         0.33333334]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.         0.         0.6666667 ]\n",
            " [0.         0.         0.         ... 0.         0.         0.08333334]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
            "(7628, 7936)\n",
            "유저피처스2 :  [[1. 0. 0. ... 0. 0. 1.]\n",
            " [0. 1. 0. ... 0. 0. 1.]\n",
            " [0. 0. 1. ... 0. 1. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n",
            "UserFeatures :  (307, 7978)\n",
            "아이템피처스2 :  [[1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "ItemFeatures :  (7628, 8010)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use the retry module or similar alternatives.\n",
            "WARNING:tensorflow:From <ipython-input-33-50abf9938573>:80: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "epoch train_error val_error elapsed_time\n",
            "  0,1.276210,1.268115,4.025748(s)\n",
            "  1,1.271510,1.261607,7.744924(s)\n",
            "  2,1.254049,1.247370,7.747019(s)\n",
            "  3,1.236125,1.238231,7.768269(s)\n",
            "  4,1.227016,1.227661,7.771881(s)\n",
            "  5,1.215582,1.219055,7.690327(s)\n",
            "  6,1.206354,1.214076,7.753912(s)\n",
            "  7,1.201796,1.209999,7.754389(s)\n",
            "  8,1.186374,1.207134,7.861920(s)\n",
            "  9,1.189313,1.204865,8.654761(s)\n",
            " 10,1.186545,1.201404,7.927588(s)\n",
            " 11,1.178557,1.196552,7.923217(s)\n",
            " 12,1.173527,1.191296,7.922321(s)\n",
            " 13,1.170357,1.184023,7.918780(s)\n",
            " 14,1.163823,1.177054,8.046664(s)\n",
            " 15,1.157026,1.169790,7.938581(s)\n",
            " 16,1.146449,1.161077,7.958658(s)\n",
            " 17,1.148865,1.152852,8.123750(s)\n",
            " 18,1.130015,1.143207,8.004713(s)\n",
            " 19,1.126908,1.134757,7.924716(s)\n",
            " 20,1.116399,1.126423,7.931050(s)\n",
            " 21,1.106784,1.120459,7.977346(s)\n",
            " 22,1.097941,1.113851,7.936707(s)\n",
            " 23,1.097269,1.107834,7.919277(s)\n",
            " 24,1.079527,1.102181,7.918979(s)\n",
            " 25,1.079659,1.096809,7.992303(s)\n",
            " 26,1.065451,1.088574,8.194520(s)\n",
            " 27,1.059800,1.082080,8.026820(s)\n",
            " 28,1.044477,1.079844,7.899698(s)\n",
            " 29,1.032154,1.075321,7.944033(s)\n",
            " 30,1.019304,1.069107,7.945125(s)\n",
            " 31,1.011138,1.064127,7.957793(s)\n",
            " 32,0.991860,1.052493,7.954177(s)\n",
            " 33,0.975304,1.051261,7.983002(s)\n",
            " 34,0.960610,1.046697,7.898734(s)\n",
            " 35,0.942585,1.031742,7.929990(s)\n",
            " 36,0.930726,1.029997,7.917614(s)\n",
            " 37,0.909454,1.032207,8.013562(s)\n",
            " 38,0.902501,1.020762,7.964203(s)\n",
            " 39,0.886794,1.022186,7.980322(s)\n",
            " 40,0.872875,1.010335,7.958752(s)\n",
            " 41,0.852880,1.012160,7.904832(s)\n",
            " 42,0.838583,1.007375,7.943833(s)\n",
            " 43,0.830401,0.997938,7.971760(s)\n",
            " 44,0.821263,1.003261,7.942837(s)\n",
            " 45,0.805249,1.013504,7.904465(s)\n",
            " 46,0.800506,0.989496,8.150307(s)\n",
            " 47,0.785633,1.007672,8.646533(s)\n",
            " 48,0.776938,1.005999,7.977584(s)\n",
            " 49,0.766683,0.999003,7.955987(s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxuN5geCIyPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}